name: Test DIRTY Ghidra's inference ability

on:
  push:
  pull_request:

  workflow_dispatch:

jobs:
  test-inference:
    # The type of runner that the job will run on
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-22.04, ubuntu-24.04]
        python-version: ["3.10", "3.11"]

    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      - uses: actions/setup-java@v4
        with:
            distribution: 'zulu' # See 'Supported distributions' for available options
            java-version: '21'
      - uses: antoniovazquezblanco/setup-ghidra@v2.0.4

      - name: Upgrade pip
        run: python -m pip install --upgrade pip setuptools wheel

      - name: Install apt dependencies
        run: sudo apt-get install -y pkg-config libsentencepiece-dev libprotobuf-dev

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download Ghidrathon
        uses: robinraju/release-downloader@v1
        with:
        # The source repository path.
        # Expected format {owner}/{repo}
        # Default: ${{ github.repository }}
          repository: mandiant/Ghidrathon
          tag: v4.0.0
          fileName: '*.zip'

      - name: Install Ghidrathon
        run: |
          mkdir ghidrathon-tmp
          unzip Ghidrathon*.zip -d ghidrathon-tmp
          pip install -r ghidrathon-tmp/requirements.txt
          python ghidrathon-tmp/ghidrathon_configure.py $GHIDRA_INSTALL_DIR
          unzip ghidrathon-tmp/Ghidrathon*.zip -d $GHIDRA_INSTALL_DIR/Ghidra/Extensions
          #$GHIDRA_INSTALL_DIR/support/analyzeHeadless projects TmpProject -import /bin/ls
      
      - name: Make projects directory
        run: mkdir -p projects

      - name: Install huggingface-cli
        run: pip install huggingface_hub[cli]

      - name: Cache model files
        uses: actions/cache@v4
        with:
          path: ${{ runner.temp }}/model-dl
          key: hf-model-dl

      - name: Download model files
        run: huggingface-cli download --repo-type model ejschwartz/dirty-ghidra --local-dir $MODEL_DL_DIR && cp -R $MODEL_DL_DIR/data1 $GITHUB_WORKSPACE/dirty/data1
        env:
          MODEL_DL_DIR: ${{ runner.temp }}/model-dl

      - name: Run DIRTY inference
        run: |
          $GHIDRA_INSTALL_DIR/support/analyzeHeadless projects MyProject -import /bin/ls -postScript $GITHUB_WORKSPACE/scripts/DIRTY_infer.py $(pwd)/infer_success.txt
          test -f infer_success.txt

      - name: Generate dataset
        run: |
          mkdir -p $DATASET_DIR
          echo $PATH # delete me
          which mkdir #delete me
          which find # delete me
          find /bin -type f | head -n 5 | xargs -I {} cp {} $DATASET_DIR
          cd $GITHUB_WORKSPACE/dataset-gen-ghidra
          python generate.py --ghidra $GHIDRA_INSTALL_DIR/support/analyzeHeadless -t 1 -b $DATASET_DIR -o $DATA_DIR/unprocessed
          python gen_names.py $DATA_DIR/unprocessed
          mv files.txt $DATA_DIR/unprocessed.txt
        env:
          DATASET_DIR: ${{ runner.temp }}/dataset
          DATA_DIR: ${{ runner.temp }}/data

      - name: Preprocess dataset
        run: |
          cd $GITHUB_WORKSPACE/dirty
          python -m utils.preprocess $DATA_DIR/unprocessed $DATA_DIR/unprocessed/files.txt $DATA_DIR/processed
          mv data1 data1.old
          mkdir data1
          python -m utils.vocab --use-bpe $DATA_DIR/processed/'train-*.tar' $DATA_DIR/processed/typelib.json data1/
        env:
          DATA_DIR: ${{ runner.temp }}/data
